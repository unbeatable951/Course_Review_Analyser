{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQUd0cgniZpz",
    "outputId": "57d124b0-1280-4bf9-8e5d-e7d257c29fd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fuzzywuzzy\n",
      "  Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eWa8fihckwZT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your datasets\n",
    "df_courses = pd.read_csv(r\"C:\\Users\\SACHIN\\OneDrive\\Desktop\\Projects(ZENITH)\\Coursera_courses.csv\")      # course names, institutions, urls\n",
    "df_stats = pd.read_csv(r\"C:\\Users\\SACHIN\\OneDrive\\Desktop\\Projects(ZENITH)\\coursea_data.csv\")            # ratings, difficulty, etc.\n",
    "df_reviews = pd.read_csv(r\"C:\\Users\\SACHIN\\OneDrive\\Desktop\\Projects(ZENITH)\\reviews.csv\")               # text reviews + sentiment labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RyRqOoyCs0Ty"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_slug(text):\n",
    "    # Extract course slug from URL or use name directly\n",
    "    if \"coursera.org\" in text:\n",
    "        match = re.search(r\"/(?:learn|specializations)/([a-zA-Z0-9\\-]+)\", text)\n",
    "        return match.group(1).replace('-', ' ') if match else text.lower()\n",
    "    else:\n",
    "        return text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.35      0.45       493\n",
      "           2       0.38      0.08      0.14       484\n",
      "           3       0.28      0.12      0.17       933\n",
      "           4       0.46      0.22      0.30      3613\n",
      "           5       0.81      0.97      0.89     15881\n",
      "\n",
      "    accuracy                           0.77     21404\n",
      "   macro avg       0.51      0.35      0.39     21404\n",
      "weighted avg       0.72      0.77      0.73     21404\n",
      "\n",
      "‚úÖ Model and vectorizer saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load review dataset\n",
    "df_reviews = pd.read_csv(r\"C:\\Users\\SACHIN\\OneDrive\\Desktop\\Projects(ZENITH)\\reviews.csv\")  # contains Review, Label\n",
    "\n",
    "# Features and labels\n",
    "X = df_reviews['Review']\n",
    "y = df_reviews['Label']\n",
    "\n",
    "# TF-IDF vectorizer (fixed max_features for consistency)\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_vec = tfidf.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=300)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, model.predict(X_test)))\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(model, \"sentiment_model.pkl\")\n",
    "joblib.dump(tfidf, \"vectorizer.pkl\")\n",
    "print(\"‚úÖ Model and vectorizer saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "I8StZsYZs3pI"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter course name or Coursera URL:  AI For Everyone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Course: AI For Everyone\n",
      "üè´ Offered by: DeepLearning.AI\n",
      "‚≠ê Rating: 4.8 / 5\n",
      "üìä Difficulty: Beginner\n",
      "üéì Enrolled: 350k students\n",
      "\n",
      "üìù Simulated Sentiment Review Summary:\n",
      "üëç Positive Reviews: 21\n",
      "üëé Negative Reviews: -16\n",
      "\n",
      "üìò Description: 'AI For Everyone' is a course offered by DeepLearning.AI on Coursera.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import difflib\n",
    "\n",
    "# Load CSVs\n",
    "df_courses = pd.read_csv(r\"C:\\Users\\SACHIN\\OneDrive\\Desktop\\Projects(ZENITH)\\Coursera_courses.csv\")      # Contains name, institution, course_id\n",
    "df_stats = pd.read_csv(r\"C:\\Users\\SACHIN\\OneDrive\\Desktop\\Projects(ZENITH)\\coursea_data.csv\")            # Contains course_title, course_rating, difficulty\n",
    "# df_reviews is not needed here, it was used during training only\n",
    "\n",
    "# Load trained model and vectorizer\n",
    "model = joblib.load(\"sentiment_model.pkl\")\n",
    "vectorizer = joblib.load(\"vectorizer.pkl\")\n",
    "\n",
    "# Helper to extract course slug from Coursera URL or input name\n",
    "def extract_slug(text):\n",
    "    if \"coursera.org\" in text:\n",
    "        parts = text.strip('/').split('/')\n",
    "        if \"learn\" in parts:\n",
    "            idx = parts.index(\"learn\")\n",
    "            if idx + 1 < len(parts):\n",
    "                return parts[idx + 1].replace(\"-\", \" \")\n",
    "    return text.lower()\n",
    "\n",
    "# Predict sentiment for sample reviews\n",
    "def predict_sentiment(text_series):\n",
    "    X = vectorizer.transform(text_series)\n",
    "    return model.predict(X)\n",
    "\n",
    "# Main analysis function\n",
    "def analyze_course(user_input):\n",
    "    slug = extract_slug(user_input)\n",
    "\n",
    "    all_names = df_courses['name'].dropna().str.lower().tolist()\n",
    "    all_ids = df_courses['course_id'].dropna().str.lower().tolist()\n",
    "    candidates = all_names + all_ids\n",
    "\n",
    "    best_match = difflib.get_close_matches(slug, candidates, n=1, cutoff=0.4)\n",
    "    if not best_match:\n",
    "        print(\"‚ùå No matching course found.\")\n",
    "        return\n",
    "\n",
    "    match = best_match[0]\n",
    "    matched = df_courses[df_courses['name'].str.lower() == match]\n",
    "    if matched.empty:\n",
    "        matched = df_courses[df_courses['course_id'].str.lower() == match]\n",
    "    if matched.empty:\n",
    "        print(\"‚ùå Still no exact match found.\")\n",
    "        return\n",
    "\n",
    "    course = matched.iloc[0]\n",
    "    course_name = course['name']\n",
    "    course_provider = course['institution']\n",
    "\n",
    "    print(f\"\\n‚úÖ Course: {course_name}\")\n",
    "    print(f\"üè´ Offered by: {course_provider}\")\n",
    "\n",
    "    # Stats (rating, difficulty, enrolled)\n",
    "    stats_match = df_stats[df_stats['course_title'].str.lower().str.contains(course_name.lower(), na=False)]\n",
    "    if not stats_match.empty:\n",
    "        stats = stats_match.iloc[0]\n",
    "        print(f\"‚≠ê Rating: {stats['course_rating']} / 5\")\n",
    "        print(f\"üìä Difficulty: {stats['course_difficulty']}\")\n",
    "        print(f\"üéì Enrolled: {stats['course_students_enrolled']} students\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No rating/difficulty info found.\")\n",
    "\n",
    "    # Simulated reviews\n",
    "    reviews = pd.Series([\n",
    "        \"Great and informative course!\",\n",
    "        \"Too basic, not what I expected.\",\n",
    "        \"Very detailed and engaging.\",\n",
    "        \"The content felt outdated.\",\n",
    "        \"Awesome projects and explanations!\"\n",
    "    ])\n",
    "    \n",
    "    sentiments = predict_sentiment(reviews)\n",
    "    pos = sum(sentiments)\n",
    "    neg = len(sentiments) - pos\n",
    "\n",
    "    print(\"\\nüìù Simulated Sentiment Review Summary:\")\n",
    "    print(f\"üëç Positive Reviews: {pos}\")\n",
    "    print(f\"üëé Negative Reviews: {neg}\")\n",
    "\n",
    "    print(f\"\\nüìò Description: '{course_name}' is a course offered by {course_provider} on Coursera.\")\n",
    "\n",
    "# Run in CLI\n",
    "user_input = input(\"Enter course name or Coursera URL: \")\n",
    "analyze_course(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "pWucEwMDhnik"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SACHIN\\\\Documents\\\\PROJECT INTERNSHIP\\\\Course review analyser'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCcKa5ZXhnft"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuHSXLJ_hndt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
